import streamlit as st
import pandas as pd
import requests
import time
from bs4 import BeautifulSoup
from io import BytesIO

# =========================================================
# 1. –¢–í–û–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø (–°–õ–û–í–ê–†–¨ –ò –õ–û–ì–ò–ö–ê –ü–†–ò–û–†–ò–¢–ï–¢–û–í)
# =========================================================
CATEGORIES = {
    # 1. –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï (QA) - —Å–∞–º–∞—è –±–æ–ª—å—à–∞—è –≥—Ä—É–ø–ø–∞ –∏–∑ —Ç–≤–æ–µ–≥–æ —Å–ø–∏—Å–∫–∞
    "QA & Automation": [
        "qa", "—Ç–µ—Å—Ç", "–∞–≤—Ç–æ—Ç–µ—Å—Ç", "—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫", "automation", "–∏—Å–ø—ã—Ç–∞–Ω–∏—è",
        "–Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–º—É —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é", "–Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ", "manual", "selenium", "apium"
    ],

    # 2. –ö–ò–ë–ï–†–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ –ò –†–ï–í–ï–†–°
    "Cybersecurity": [
        "–ø–µ–Ω—Ç–µ—Å—Ç–µ—Ä", "pentest", "security", "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "reverse", "—Ä–µ–≤–µ—Ä—Å", 
        "appsec", "soc", "siem", "–∫–∏–±–µ—Ä", "–¥–æ—Å—Ç—É–ø–æ–≤", "–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"
    ],

    # 3. –ò–°–ö–£–°–°–¢–í–ï–ù–ù–´–ô –ò–ù–¢–ï–õ–õ–ï–ö–¢ –ò –î–ê–ù–ù–´–ï
    "AI & Data": [
        "llm", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "ai", "ml", "prompt", "–ø—Ä–æ–º–ø—Ç",
        "data analyst", "–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö", "bi", "sql", "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏", "computer vision"
    ],

    # 4. –°–ò–°–¢–ï–ú–ù–û–ï –ò –°–ï–¢–ï–í–û–ï –ò–ù–ñ–ï–ù–ï–†–°–¢–í–û
    "System & Network": [
        "—Å–∏—Å—Ç–µ–º–Ω—ã–π –∏–Ω–∂–µ–Ω–µ—Ä", "kubernetes", "k8s", "voip", "asterisk", "—Å–µ—Ç–µ–≤–æ–π",
        "—Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä", "sysadmin", "linux", "sre", "devops"
    ],

    # 5. –ò–ù–ñ–ï–ù–ï–†–ò–Ø –ò –ê–°–£ –¢–ü (–ü–†–û–ú–´–®–õ–ï–ù–ù–û–°–¢–¨)
    "Industrial Engineering": [
        "–∞—Å—É —Ç–ø", "—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫", "—ç–ª–µ–∫—Ç—Ä–æ–Ω—â–∏–∫", "—Ä–∞–¥–∏–æ—ç–ª–µ–∫—Ç—Ä–æ–Ω", "–ø–ª–∏—Å", 
        "fpga", "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏", "dsp", "sdr"
    ],

    # 6. IT-HR –ò –û–ë–£–ß–ï–ù–ò–ï
    "HR & Education": [
        "—Ä–µ–∫—Ä—É—Ç–µ—Ä", "recruiter", "–æ–±—É—á–µ–Ω–∏—é", "—Ä–∞–∑–≤–∏—Ç–∏—é", "–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å", 
        "—É—á–∏—Ç–µ–ª—å", "–º–µ—Ç–æ–¥–∏—Å—Ç", "–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫"
    ],

    # 7. –†–ê–ó–†–ê–ë–û–¢–ö–ê (Backend, Frontend, Fullstack)
    "Development": [
        "—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫", "developer", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç", "backend", "frontend", 
        "fullstack", "gamedev", "python", "java", "c#", ".net"
    ],

    # 8. –ü–û–î–î–ï–†–ñ–ö–ê –ò –ê–ù–ê–õ–ò–ó (–ë–ò–ó–ù–ï–°)
    "Support & Analysis": [
        "–ø–æ–¥–¥–µ—Ä–∂–∫", "helpdesk", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç", "—Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫", 
        "–±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫", "product", "project", "–º–µ–Ω–µ–¥–∂–µ—Ä"
    ]
}

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: QA —Å—Ç–∞–≤–∏–º –≤—ã—à–µ Development, —á—Ç–æ–±—ã "QA Python Engineer" –ø–æ–ø–∞–ª –≤ QA, –∞ –Ω–µ –≤ Dev.
PRIORITY = [
    "QA & Automation", "Cybersecurity", "AI & Data", "System & Network",
    "Industrial Engineering", "HR & Education", "Development", "Support & Analysis"
]

def classify_title(title):
    # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç —Ç–∏—Ä–µ –∏ —Å–ª–µ—à–µ–π, —á—Ç–æ–±—ã "QA-–∏–Ω–∂–µ–Ω–µ—Ä" —Å—Ç–∞–ª "QA –∏–Ω–∂–µ–Ω–µ—Ä"
    title = str(title).lower().replace('-', ' ').replace('/', ' ').strip()

    scores = {cat: 0 for cat in CATEGORIES}

    for category in PRIORITY:
        for keyword in CATEGORIES[category]:
            # –ò—â–µ–º –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –∫–∞–∫ –ø–æ–¥—Å—Ç—Ä–æ–∫—É
            if keyword.lower() in title:
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø—Ä—è–º–æ–µ –ø–æ–ø–∞–¥–∞–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ø–µ–Ω—Ç–µ—Å—Ç–µ—Ä"), 
                # –¥–∞–µ–º —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–æ–ª—å—à–æ–π –≤–µ—Å
                scores[category] += 5 
    
    best_category = max(scores, key=scores.get)

    if scores[best_category] == 0:
        return "Other"

    return best_category

# =========================================================
# 2. –§–£–ù–ö–¶–ò–ò –ü–ê–†–°–ò–ù–ì–ê (HH.RU API + BS4)
# =========================================================
@st.cache_data
def get_area_id_by_city(city_name):
    try:
        res = requests.get("https://api.hh.ru/areas")
        areas = res.json()
        def search(areas_list):
            for a in areas_list:
                if a["name"].lower() == city_name.lower(): return a["id"]
                if a.get("areas"):
                    r = search(a["areas"])
                    if r: return r
            return None
        return search(areas)
    except: return None

def fetch_full_description(url):
    try:
        r = requests.get(url, headers={"User-Agent": "HH-Parser/1.0"}, timeout=5)
        soup = BeautifulSoup(r.text, "html.parser")
        block = soup.find("div", {"data-qa": "vacancy-description"}) or soup.find("div", class_="g-user-content")
        return block.get_text(separator="\n").strip() if block else ""
    except: return ""

def start_parsing(text, city_name, max_pages):
    area_id = get_area_id_by_city(city_name)
    if not area_id: return None, "–ì–æ—Ä–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω"

    all_vacancies = []
    status_container = st.empty() 
    progress_bar = st.progress(0)

    for page in range(max_pages):
        params = {"text": text, "area": area_id, "per_page": 20, "page": page}
        res = requests.get("https://api.hh.ru/vacancies", params=params)
        if res.status_code != 200: break
        
        items = res.json().get("items", [])
        if not items: break

        for item in items:
            name = item.get("name")
            url = item.get("alternate_url")
            status_container.info(f"‚è≥ –ü–∞—Ä—Å–∏–º: {name[:40]}...")
            
            desc = fetch_full_description(url)
            salary = item.get("salary")
            
            all_vacancies.append({
                "name": name,
                "category": classify_title(name),
                "company": item.get("employer", {}).get("name"),
                "city": city_name,
                "salary_from": salary["from"] if salary else None,
                "salary_to": salary["to"] if salary else None,
                "currency": salary["currency"] if salary else None,
                "experience": item.get("experience", {}).get("name", "–ù–µ —É–∫–∞–∑–∞–Ω"),
                "url": url,
                "description": desc
            })
            time.sleep(0.1) 
        
        progress_bar.progress((page + 1) / max_pages)
    
    status_container.success("‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    return pd.DataFrame(all_vacancies), None

# =========================================================
# 3. –ò–ù–¢–ï–†–§–ï–ô–° STREAMLIT
# =========================================================
st.header("üîé –°–±–æ—Ä –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–∞–∫–∞–Ω—Å–∏–π")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞
if 'vacancies_df' not in st.session_state:
    st.session_state['vacancies_df'] = None
if 'selected_category' not in st.session_state:
    st.session_state['selected_category'] = "–í—Å–µ"

# –§–æ—Ä–º–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
with st.form("parser_settings"):
    col1, col2 = st.columns(2)
    city_in = col1.text_input("–í–≤–µ–¥–∏—Ç–µ –≥–æ—Ä–æ–¥", value="–£—Ñ–∞")
    query_in = col2.text_input("–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ", value="Python")
    limit_in = st.slider("–°–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü –∏—Å–∫–∞—Ç—å?", 1, 10, 2)
    submit = st.form_submit_button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å")

if submit:
    df_result, err = start_parsing(query_in, city_in, limit_in)
    if err:
        st.error(err)
    else:
        st.session_state['vacancies_df'] = df_result
        st.session_state['selected_category'] = "–í—Å–µ" # –°–±—Ä–æ—Å —Ñ–∏–ª—å—Ç—Ä–∞ –ø—Ä–∏ –Ω–æ–≤–æ–º –ø–æ–∏—Å–∫–µ

# –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
if st.session_state['vacancies_df'] is not None:
    df = st.session_state['vacancies_df']
    
    st.divider()
    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è")
    
    # 1. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ "–ú–µ—Ç—Ä–∏–∫–∏-–∫–Ω–æ–ø–∫–∏"
    cat_counts = df["category"].value_counts()
    
    st.write("–ö–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é, —á—Ç–æ–±—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É:")
    
    # –ö–Ω–æ–ø–∫–∞ —Å–±—Ä–æ—Å–∞
    if st.button("üîÑ –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏"):
        st.session_state['selected_category'] = "–í—Å–µ"

    # –°–µ—Ç–∫–∞ –∫–Ω–æ–ø–æ–∫
    cols = st.columns(min(len(cat_counts), 5))
    for i, (cat, count) in enumerate(cat_counts.items()):
        if cols[i % 5].button(f"{cat}: {count}"):
            st.session_state['selected_category'] = cat

    # 2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    if st.session_state['selected_category'] == "–í—Å–µ":
        display_df = df
        st.info("–°–µ–π—á–∞—Å –ø–æ–∫–∞–∑–∞–Ω—ã **–≤—Å–µ** –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏.")
    else:
        display_df = df[df["category"] == st.session_state['selected_category']]
        st.success(f"–ü–æ–∫–∞–∑–∞–Ω—ã –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: **{st.session_state['selected_category']}**")

    # 3. –¢–∞–±–ª–∏—Ü–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏
    st.dataframe(
        display_df, 
        use_container_width=True,
        column_config={
            "url": st.column_config.LinkColumn("–°—Å—ã–ª–∫–∞ –Ω–∞ HH.ru")
        }
    )

    # 4. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ (–≤—Å–µ–≥–¥–∞ –ø–æ–ª–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)
    st.divider()
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False)
    
    st.download_button(
        label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π Excel",
        data=output.getvalue(),
        file_name=f"vacancies_{city_in}.xlsx",
        mime="application/vnd.ms-excel"
    )
    
    st.info("üí° –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–º—è—Ç–∏. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª **–ê–Ω–∞–ª–∏—Ç–∏–∫–∞** –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤.")
else:
    st.info("–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã—à–µ –∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –¥–ª—è –Ω–∞—á–∞–ª–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.")